# -*- coding: utf-8 -*-
"""MachineLearning_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12aOcdgzeWMS8eRStfP6zMs9T9sNqHTP3
"""

import numpy as np # Библиотека numpy как объект np 
import torch
import time

"""Самойленко Максим Андреевич

Максимальное приращение времени происходит при n = 100000. GPU имеет время ~ 1.4
CPU имеет время ~ 20.1 
При малых n таких как: 10,50,100 видно, что процессор считает быстрее, чем видеокарта. При n:1000, 2000,5000, 10000 видеокарта считает быстрее. 
При n = 1000 - происходит переломный момент, когда видеокарта считает быстрее, чем процессор.
"""

n = 10
A_CPU = np.random.random([n,n])
b_CPU = np.random.random([n,1])
t0 = time.time()
x_CPU = np.linalg.solve(A_CPU,b_CPU)
print(f'Your code on numpy runtime is {time.time()-t0}')
torch.cuda.get_device_name(0)
A_GPU = torch.from_numpy(A_CPU).cuda()
b_GPU = torch.from_numpy(b_CPU).cuda()
t0 = time.time()
x_GPU = torch.solve(b_GPU,A_GPU)
print(f'Your code on GPU runtime is {time.time()-t0}')

n = 50
A_CPU = np.random.random([n,n])
b_CPU = np.random.random([n,1])
t0 = time.time()
x_CPU = np.linalg.solve(A_CPU,b_CPU)
print(f'Your code on numpy runtime is {time.time()-t0}')
torch.cuda.get_device_name(0)
A_GPU = torch.from_numpy(A_CPU).cuda()
b_GPU = torch.from_numpy(b_CPU).cuda()
t0 = time.time()
x_GPU = torch.solve(b_GPU,A_GPU)
print(f'Your code on GPU runtime is {time.time()-t0}')

n = 100
A_CPU = np.random.random([n,n])
b_CPU = np.random.random([n,1])
t0 = time.time()
x_CPU = np.linalg.solve(A_CPU,b_CPU)
print(f'Your code on numpy runtime is {time.time()-t0}')
torch.cuda.get_device_name(0)
A_GPU = torch.from_numpy(A_CPU).cuda()
b_GPU = torch.from_numpy(b_CPU).cuda()
t0 = time.time()
x_GPU = torch.solve(b_GPU,A_GPU)
print(f'Your code on GPU runtime is {time.time()-t0}')

n = 1000
A_CPU = np.random.random([n,n])
b_CPU = np.random.random([n,1])
t0 = time.time()
x_CPU = np.linalg.solve(A_CPU,b_CPU)
print(f'Your code on numpy runtime is {time.time()-t0}')
torch.cuda.get_device_name(0)
A_GPU = torch.from_numpy(A_CPU).cuda()
b_GPU = torch.from_numpy(b_CPU).cuda()
t0 = time.time()
x_GPU = torch.solve(b_GPU,A_GPU)
print(f'Your code on GPU runtime is {time.time()-t0}')

n = 2000
A_CPU = np.random.random([n,n])
b_CPU = np.random.random([n,1])
t0 = time.time()
x_CPU = np.linalg.solve(A_CPU,b_CPU)
print(f'Your code on numpy runtime is {time.time()-t0}')
torch.cuda.get_device_name(0)
A_GPU = torch.from_numpy(A_CPU).cuda()
b_GPU = torch.from_numpy(b_CPU).cuda()
t0 = time.time()
x_GPU = torch.solve(b_GPU,A_GPU)
print(f'Your code on GPU runtime is {time.time()-t0}')

n = 5000
A_CPU = np.random.random([n,n])
b_CPU = np.random.random([n,1])
t0 = time.time()
x_CPU = np.linalg.solve(A_CPU,b_CPU)
print(f'Your code on numpy runtime is {time.time()-t0}')
torch.cuda.get_device_name(0)
A_GPU = torch.from_numpy(A_CPU).cuda()
b_GPU = torch.from_numpy(b_CPU).cuda()
t0 = time.time()
x_GPU = torch.solve(b_GPU,A_GPU)
print(f'Your code on GPU runtime is {time.time()-t0}')

n = 10000
A_CPU = np.random.random([n,n])
b_CPU = np.random.random([n,1])
t0 = time.time()
x_CPU = np.linalg.solve(A_CPU,b_CPU)
print(f'Your code on numpy runtime is {time.time()-t0}')
torch.cuda.get_device_name(0)
A_GPU = torch.from_numpy(A_CPU).cuda()
b_GPU = torch.from_numpy(b_CPU).cuda()
t0 = time.time()
x_GPU = torch.solve(b_GPU,A_GPU)
print(f'Your code on GPU runtime is {time.time()-t0}')
